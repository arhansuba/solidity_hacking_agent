from slither import Slither
from mythril import Mythril
from manticore import Manticore
from typing import List, Dict, Any
from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent
from langchain.prompts import StringPromptTemplate
from langchain import OpenAI, LLMChain
from langchain.schema import AgentAction, AgentFinish
from pydantic import BaseModel, Field
import re

class VulnerabilityScannerAgent(BaseModel):
    llm: Any = Field(default_factory=lambda: OpenAI(temperature=0.1))
    tools: List[Tool] = Field(default_factory=list)

    class Config:
        arbitrary_types_allowed = True

    def __init__(self, **data):
        super().__init__(**data)
        self.tools = [
            Tool(
                name="Static Analysis",
                func=self.static_analysis,
                description="Performs static analysis on the smart contract code"
            ),
            Tool(
                name="Dynamic Analysis",
                func=self.dynamic_analysis,
                description="Performs dynamic analysis on the smart contract code"
            ),
            Tool(
                name="Symbolic Execution",
                func=self.symbolic_execution,
                description="Performs symbolic execution on the smart contract code"
            )
        ]

    def static_analysis(self, contract_code: str) -> str:
        # This is a placeholder for actual static analysis logic
        vulnerabilities = []
        if "selfdestruct" in contract_code:
            vulnerabilities.append("Potential use of selfdestruct detected. This can be dangerous if not properly secured.")
        if "delegatecall" in contract_code:
            vulnerabilities.append("Use of delegatecall detected. Ensure it's used securely to prevent potential vulnerabilities.")
        if "tx.origin" in contract_code:
            vulnerabilities.append("Use of tx.origin detected. This can be manipulated by attackers in certain scenarios.")
        return "\n".join(vulnerabilities) if vulnerabilities else "No vulnerabilities detected in static analysis."

    def dynamic_analysis(self, contract_code: str) -> str:
        # This is a placeholder for actual dynamic analysis logic
        return "Dynamic analysis complete. No critical vulnerabilities detected during execution."

    def symbolic_execution(self, contract_code: str) -> str:
        # This is a placeholder for actual symbolic execution logic
        return "Symbolic execution complete. Potential integer overflow detected in function X."

    def scan_contract(self, contract_code: str) -> Dict[str, Any]:
        prompt = StringPromptTemplate(
            input_variables=["input", "tools"],
            template="Scan this smart contract for vulnerabilities: {input}\n\nAvailable tools: {tools}\n\nResponse:"
        )

        llm_chain = LLMChain(llm=self.llm, prompt=prompt)
        agent = LLMSingleActionAgent(
            llm_chain=llm_chain,
            output_parser=self.output_parser,
            stop=["\nObservation:"],
            allowed_tools=[tool.name for tool in self.tools]
        )
        agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=self.tools, verbose=True)
        
        results = agent_executor.run(contract_code)
        return {
            "static_analysis": self.static_analysis(contract_code),
            "dynamic_analysis": self.dynamic_analysis(contract_code),
            "symbolic_execution": self.symbolic_execution(contract_code),
            "overall_results": results
        }

    @staticmethod
    def output_parser(llm_output: str) -> AgentAction | AgentFinish:
        if "Final Answer:" in llm_output:
            return AgentFinish(
                return_values={"output": llm_output.split("Final Answer:")[-1].strip()},
                log=llm_output,
            )
        regex = r"Action: (.*?)[\n]*Action Input:[\s]*(.*)"
        match = re.search(regex, llm_output, re.DOTALL)
        if not match:
            raise ValueError(f"Could not parse LLM output: `{llm_output}`")
        action = match.group(1).strip()
        action_input = match.group(2)
        return AgentAction(tool=action, tool_input=action_input.strip(" ").strip('"'), log=llm_output)

if __name__ == "__main__":
    scanner = VulnerabilityScannerAgent()
    contract_code = """
    pragma solidity ^0.8.0;

    contract Vulnerable {
        function destroy() public {
            selfdestruct(payable(msg.sender));
        }
    }
    """
    results = scanner.scan_contract(contract_code)
    print(results)
def scan_contracts(contract_path):
    # Initialize tools
    slither = Slither(contract_path)
    mythril = Mythril(contract_path)
    manticore = Manticore(contract_path)
    
    # Run scans
    slither_report = slither.run_analysis()
    mythril_report = mythril.run_analysis()
    manticore_report = manticore.run_analysis()

    # Process reports
    return {
        'slither': slither_report,
        'mythril': mythril_report,
        'manticore': manticore_report
    }

if __name__ == "__main__":
    import sys
    contract_path = sys.argv[1]
    reports = scan_contracts(contract_path)
    print(reports)
